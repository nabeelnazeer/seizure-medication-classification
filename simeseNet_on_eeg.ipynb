{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52385b7-06f2-4083-8f31-fa247326300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras import backend as K\n",
    "from keras import Input, Model\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, concatenate\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed79743e-9b30-4b37-85e8-e39409653d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dilantin_path = 'Siezure med dataset/dataset_used_in_CBMS_paper/fft_images_100Hz_ws_1_overlap_0.1_1Hz_50Hz/dilantin'\n",
    "keppra_path = 'Siezure med dataset/dataset_used_in_CBMS_paper/fft_images_100Hz_ws_1_overlap_0.1_1Hz_50Hz/keppra'\n",
    "none_path = 'Siezure med dataset/dataset_used_in_CBMS_paper/fft_images_100Hz_ws_1_overlap_0.1_1Hz_50Hz/none_0.15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3fcb85-e6e3-46c0-b21d-2900ffce370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder_path,label):\n",
    "    data  = []\n",
    "    file_list = os.listdir(folder_path)\n",
    "    npy_files  =  [f for f in file_list if f.endswith('.npy')]\n",
    "\n",
    "    \n",
    "    for file in npy_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            loaded_data = np.load(file_path)\n",
    "            \n",
    "            num_samples = loaded_data.shape[0]\n",
    "            data.extend([(loaded_data[i], label) for i in range(num_samples)])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad9c9a2-d6b7-4592-b7ff-cf8466511343",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilantin_data =  get_data(dilantin_path, 0)\n",
    "keppra_data = get_data(keppra_path, 1)\n",
    "none_path = get_data(none_path, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938e7de6-a057-41ca-9202-cede49bdf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(dataset, max_samples=100000, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Split dataset into training and test sets with a maximum of max_samples samples.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: A list of tuples where each tuple contains (sample, label).\n",
    "    - max_samples: The maximum number of samples to include from the dataset (default=100000).\n",
    "    - test_size: The proportion of the dataset to include in the test split (default=0.2).\n",
    "    - random_state: Controls the shuffling applied to the data before applying the split.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing (x_train, x_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    # Limit the dataset size to max_samples\n",
    "    if len(dataset) > max_samples:\n",
    "        dataset = dataset[:max_samples]\n",
    "\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for sample, label in dataset:\n",
    "        x_data.append(sample)\n",
    "        y_data.append(label)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87e48c6-4961-4dde-a8d3-8786f049d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dilantin, x_test_dilantin, y_train_dilantin, y_test_dilantin = split_data(dilantin_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f522e2d3-7ba8-4e46-9966-62a0705c188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_keppra, x_test_keppra, y_train_keppra, y_test_keppra = split_data(keppra_data, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ace7686-a4de-4c3a-ac71-67c074710ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_none, x_test_none, y_train_none, y_test_none = split_data(none_path, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b1b0e4-a518-4cd5-bc5f-eb86d6ba1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train_dilantin, x_train_keppra, x_train_none), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba878ea4-e06d-4a95-bdeb-c9d8cdfa3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train_dilantin, y_train_keppra, y_train_none), axis=0)\n",
    "\n",
    "x_test = np.concatenate((x_test_dilantin, x_test_keppra, x_test_none), axis=0)\n",
    "y_test = np.concatenate((y_test_dilantin, y_test_keppra, y_test_none), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f2e5b2-7c29-496d-9542-9b31038afff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train.reshape(x_train.shape[0], 19, 50, 1).astype('float32') / 255\n",
    "# x_test = x_test.reshape(x_test.shape[0], 19, 50, 1).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee322ef-f5a6-47c1-97ce-7b47a10c1aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240000, 19, 50), (240000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf3490e6-266f-4496-bf8d-23f92f38febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets(x_train, y_train, batch_size=32):\n",
    "    while True:\n",
    "        anchors_list = []\n",
    "        positive_list = []\n",
    "        negative_list = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            anchor_index = np.random.choice(len(x_train))\n",
    "            anchor = x_train[anchor_index]\n",
    "            label = y_train[anchor_index]\n",
    "            \n",
    "            positive_indices = np.where(y_train == label)[0]\n",
    "            positive_index = np.random.choice(positive_indices)\n",
    "            positive = x_train[positive_index]\n",
    "\n",
    "            negative_indices = np.where(y_train!= label)[0]\n",
    "            negative_index = np.random.choice(negative_indices)\n",
    "            negative = x_train[negative_index]\n",
    "\n",
    "            anchors_list.append(anchor)\n",
    "            positive_list.append(positive)\n",
    "            negative_list.append(negative)\n",
    "        \n",
    "        # Convert lists to NumPy arrays and apply reshaping and normalization\n",
    "        anchors = np.array(anchors_list).reshape(-1, 19, 50, 1).astype('float32') / 255\n",
    "        positives = np.array(positive_list).reshape(-1, 19, 50, 1).astype('float32') / 255\n",
    "        negatives = np.array(negative_list).reshape(-1, 19, 50, 1).astype('float32') / 255\n",
    "\n",
    "        # Convert NumPy arrays to TensorFlow tensors\n",
    "        anchors_tf = tf.convert_to_tensor(anchors)\n",
    "        positives_tf = tf.convert_to_tensor(positives)\n",
    "        negatives_tf = tf.convert_to_tensor(negatives)\n",
    "\n",
    "        \n",
    "        yield [anchors_tf, positives_tf, negatives_tf], tf.zeros((batch_size,))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65f30e87-83d8-459e-acb9-175f86b909ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, margin = 0.2):\n",
    "    anchor, positive, negative = y_pred[:, 0:64], y_pred[:, 64:128], y_pred[:, 128:]\n",
    "    \n",
    "    positive_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "    negative_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "    \n",
    "    loss = tf.maximum(positive_dist - negative_dist + margin, 0.0)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7b01ea-0ada-4368-9974-e12c0583a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_network(input_shape):\n",
    "    inputs= Input(shape = input_shape)\n",
    "    x = Conv2D(32, (3,3), activation = 'relu')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(64)(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "input_shape = (19, 50, 1)\n",
    "\n",
    "common_network = common_network(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98dcda90-1e6c-4c1d-9802-d5f783d22e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ anchor_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positive_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ negative_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,351,040</span> │ anchor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ positive_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ negative_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ anchor_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positive_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ negative_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │  \u001b[38;5;34m3,351,040\u001b[0m │ anchor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ positive_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ negative_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ functional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ functional_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,351,040</span> (12.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,351,040\u001b[0m (12.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,351,040</span> (12.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,351,040\u001b[0m (12.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anchor_input = Input(shape=input_shape, name='anchor_input')\n",
    "positive_input = Input(shape=input_shape, name='positive_input')\n",
    "negative_input = Input(shape=input_shape, name='negative_input')\n",
    "\n",
    "encoded_anchor = common_network(anchor_input)\n",
    "encoded_positive = common_network(positive_input)\n",
    "encoded_negative = common_network(negative_input)\n",
    "\n",
    "merged_output = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1)\n",
    "\n",
    "triplet_model = Model(inputs=[anchor_input, positive_input, negative_input], outputs=merged_output)\n",
    "triplet_model.compile(optimizer = 'adam', loss = triplet_loss)\n",
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e13032c4-6572-40ba-b7cb-4f34bcf1a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_generator = generate_triplets(x_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83197cf1-9db7-4cc2-995f-27d108bce055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([32, 19, 50, 1]), TensorShape([32, 19, 50, 1]), TensorShape([32, 19, 50, 1])] (32,)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_generator:\n",
    "    print([input_.shape for input_ in inputs], targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab6aa9c3-a0b8-49a8-98c3-0e4c5d893416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4958f628-b7a7-4214-a9d1-b30bef611616",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtriplet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_triplets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py:124\u001b[0m, in \u001b[0;36m_from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(output_signature):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, type_spec\u001b[38;5;241m.\u001b[39mTypeSpec):\n\u001b[0;32m--> 124\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`output_signature` must contain objects that are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclass of `tf.TypeSpec` but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is not.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m output_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "triplet_model.fit(generate_triplets(x_train, y_train, batch_size=32), steps_per_epoch=len(x_train) // 32, epochs=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
